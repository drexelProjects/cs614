{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88011d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"iamhungundji/dysarthria-detection\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99f9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, json, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from joblib import dump\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "DATA_DIR = \"/home/sraja/.cache/kagglehub/datasets/iamhungundji/dysarthria-detection/versions/1\"\n",
    "\n",
    "DYS_SPEAKERS     = {\"F01\", \"F03\", \"F04\", \"M01\", \"M02\", \"M03\"} \n",
    "HEALTHY_SPEAKERS = {\"FC01\", \"FC02\", \"MC01\", \"MC02\"} \n",
    "\n",
    "KEYWORDS_DYS = (\"dys\", \"dysarth\")     # path contains any → label=1\n",
    "KEYWORDS_CTL = (\"control\", \"healthy\") # path contains any → label=0\n",
    "\n",
    "# Audio extensions to include:\n",
    "EXTS = (\".wav\", \".flac\", \".mp3\", \".ogg\")\n",
    "\n",
    "CALL_WAV = \"dysarthia.wav\"#nonDysarthia\n",
    "\n",
    "# Feature parameters\n",
    "SAMPLE_RATE = 16_000\n",
    "N_MFCC = 13 \n",
    "\n",
    "# Cache features to speed up re-runs (creates .npy alongside audio)\n",
    "ENABLE_FEATURE_CACHE = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab01a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "spk_regex = re.compile(r\"(?:^|/)([FM][C]?\\d{2})(?:/|_)\")  # matches F01, M03, FC01, MC02 etc.\n",
    "\n",
    "def extract_speaker_id(path: str) -> str:\n",
    "    m = spk_regex.search(path.replace(\"\\\\\", \"/\"))\n",
    "    return m.group(1) if m else os.path.basename(os.path.dirname(path))\n",
    "\n",
    "def label_from_path(path: str, speaker_id: str) -> int | None:\n",
    "    # Priority 1: explicit speaker lists\n",
    "    if speaker_id in DYS_SPEAKERS: return 1\n",
    "    if speaker_id in HEALTHY_SPEAKERS: return 0\n",
    "    # Priority 2: keywords\n",
    "    p = path.lower()\n",
    "    if any(k in p for k in KEYWORDS_DYS): return 1\n",
    "    if any(k in p for k in KEYWORDS_CTL): return 0\n",
    "    return None  # unknown\n",
    "\n",
    "def list_audio_files(root: str, exts=EXTS) -> list[str]:\n",
    "    files = []\n",
    "    for ext in exts:\n",
    "        files.extend(glob.glob(os.path.join(root, \"**\", f\"*{ext}\"), recursive=True))\n",
    "    return sorted(files)\n",
    "\n",
    "def feat_cache_path(audio_path: str) -> str:\n",
    "    base_dir = os.path.dirname(audio_path)\n",
    "    if not base_dir:\n",
    "        base_dir = \"cache_feats\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    return os.path.splitext(audio_path)[0] + f\".mfcc{N_MFCC}.sr{SAMPLE_RATE}.npy\"\n",
    "\n",
    "def extract_features(audio_path: str, n_mfcc: int = N_MFCC, sr: int = SAMPLE_RATE) -> np.ndarray:\n",
    "    \"\"\"Extract MFCCs -> mean over time (shape: [n_mfcc]). Uses cache if enabled.\"\"\"\n",
    "    if ENABLE_FEATURE_CACHE:\n",
    "        cache = feat_cache_path(audio_path)\n",
    "        if os.path.exists(cache):\n",
    "            return np.load(cache)\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    # trim leading/trailing silence to reduce noise\n",
    "    y, _ = librosa.effects.trim(y, top_db=25)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    x = mfcc.mean(axis=1).astype(np.float32)\n",
    "    if ENABLE_FEATURE_CACHE:\n",
    "        os.makedirs(os.path.dirname(cache), exist_ok=True)\n",
    "        np.save(cache, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dc0269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features: (1996, 13), dysarthric=1478, healthy=518, skipped=1\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "all_wavs = list_audio_files(DATA_DIR, EXTS)\n",
    "if not all_wavs:\n",
    "    raise FileNotFoundError(f\"No audio found under {DATA_DIR}. Check DATA_DIR and extensions {EXTS}\")\n",
    "\n",
    "X, y, groups, paths = [], [], [], []\n",
    "skipped = 0\n",
    "for ap in all_wavs:\n",
    "    sid = extract_speaker_id(ap)\n",
    "    lab = label_from_path(ap, sid)\n",
    "    if lab is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    try:\n",
    "        X.append(extract_features(ap))\n",
    "        y.append(lab)\n",
    "        groups.append(sid)  # group by speaker to prevent leakage\n",
    "        paths.append(ap)\n",
    "    except Exception as e:\n",
    "        skipped += 1\n",
    "\n",
    "X = np.vstack(X)\n",
    "y = np.asarray(y, dtype=np.int64)\n",
    "groups = np.asarray(groups)\n",
    "\n",
    "print(f\"Loaded features: {X.shape}, dysarthric={int(y.sum())}, healthy={int((y==0).sum())}, skipped={skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d92238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'svm__C': 4, 'svm__gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# TRAIN / VAL SPLIT (by speaker)\n",
    "# -----------------------\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "(train_idx, val_idx), = gss.split(X, y, groups)\n",
    "\n",
    "X_train, X_val = X[train_idx], X[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# -----------------------\n",
    "# MODEL (SVM with RBF) + scaling\n",
    "# -----------------------\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svm__C\": [0.5, 1, 2, 4],\n",
    "    \"svm__gamma\": [\"scale\", 0.01, 0.001]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, scoring=\"roc_auc\", refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best params: {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f0176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.696\n",
      "Validation ROC-AUC: 0.788\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   healthy(0)       0.94      0.46      0.61       169\n",
      "dysarthric(1)       0.61      0.97      0.75       150\n",
      "\n",
      "     accuracy                           0.70       319\n",
      "    macro avg       0.78      0.71      0.68       319\n",
      " weighted avg       0.79      0.70      0.68       319\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 77  92]\n",
      " [  5 145]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation accuracy: {acc:.3f}\")\n",
    "\n",
    "try:\n",
    "    y_prob = clf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_prob)\n",
    "    print(f\"Validation ROC-AUC: {auc:.3f}\")\n",
    "except Exception:\n",
    "    y_prob = None\n",
    "    print(\"Validation ROC-AUC: n/a (single class in val set?)\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=[\"healthy(0)\",\"dysarthric(1)\"]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce931990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved model → models/torgo_speech_svc.joblib\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_path = \"models/torgo_speech_svc.joblib\"\n",
    "dump({\n",
    "    \"model\": clf.best_estimator_,\n",
    "    \"params\": clf.best_params_,\n",
    "    \"n_mfcc\": N_MFCC,\n",
    "    \"sr\": SAMPLE_RATE,\n",
    "    \"label_map\": {\"healthy\": 0, \"dysarthric\": 1}\n",
    "}, model_path)\n",
    "print(f\"\\nSaved model → {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7822b6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speech-based stroke probability for 'dysarthia.wav': 97.53%\n"
     ]
    }
   ],
   "source": [
    "def predict_stroke_probability(model_obj, audio_path: str) -> float:\n",
    "    x = extract_features(audio_path).reshape(1, -1)\n",
    "    return float(model_obj.predict_proba(x)[0, 1])\n",
    "\n",
    "if CALL_WAV and os.path.exists(CALL_WAV):\n",
    "    from joblib import load\n",
    "    pack = load(model_path)\n",
    "    svc = pack[\"model\"]\n",
    "    prob = predict_stroke_probability(svc, CALL_WAV)\n",
    "    print(f\"\\nSpeech-based stroke probability for '{CALL_WAV}': {prob:.2%}\")\n",
    "else:\n",
    "    if CALL_WAV:\n",
    "        print(f\"\\nCALL_WAV not found at '{CALL_WAV}'. Skipping demo prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46793b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
